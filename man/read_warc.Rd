% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/read-warc.r
\name{read_warc}
\alias{read_warc}
\title{Read a WARC file}
\usage{
read_warc(path, warc_types = NULL, include_payload = FALSE)
}
\arguments{
\item{path}{path to WARF file}

\item{warc_types}{if not \code{NULL} and one or more of \code{warcinfo}, \code{request}, \code{response},
\code{resource}, \code{metadata}, \code{revisit}, \code{conversion} then returned WARC records
will be filtered to only include the specified record types.}

\item{include_payload}{if \code{TRUE} then the payload for each WARC record will
be included.}
}
\description{
The API for this functiuon is likely to change since this is a WIP. Optimizations
will be occurring at the Java-level as well (this was a lazy PoC implementation).
}
\note{
Presently only works with gzip'd WARC files (but they are most common)
}
\section{Reading Large WARC files}{


Typical WARC files from sources like Common Crawl \url{http://commoncrawl.org/the-data/}
are between 100 MB and ~1 GB in size (compressed). Since the goal of \code{read_warc()} is
to bring a WARC file into an R data frame, said data frames can become quite large
(proportional to the size of the WARC file). You may need to do the following at the
top of scripts or at the start of an R session to ensure the JVM has enough room
to accommodate the vectors used in the data frame creation:\preformatted{options(java.parameters = "-Xmx2g")
}

The \code{2g} value may need to be higher in specific use cases.

Functions will eventually be provided to "stream process" WARC files vs read them
all into memory.
}

\examples{
read_warc(system.file("extdata/sample.warc.gz", package="jwatr"),
          warc_types = "response", include_payload = FALSE)
}
